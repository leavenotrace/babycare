import os.path

from libs.helper import *
import streamlit as st
import uuid
import pandas as pd
import openai
from requests.models import ChunkedEncodingError
from streamlit.components import v1
from voice_toolkit import voice_toolkit

if "apibase" in st.secrets:
    openai.api_base = st.secrets["apibase"]
else:
    openai.api_base = "https://api.openai.com/v1"

st.set_page_config(page_title="AIä¼´å®å®", layout="wide", page_icon="ğŸ¤–")
# è‡ªå®šä¹‰å…ƒç´ æ ·å¼
st.markdown(css_code, unsafe_allow_html=True)

if "initial_settings" not in st.session_state:
    # å†å²èŠå¤©çª—å£
    st.session_state["path"] = "history_chats_file"
    st.session_state["history_chats"] = get_history_chats(st.session_state["path"])
    # sså‚æ•°åˆå§‹åŒ–
    st.session_state["delete_dict"] = {}
    st.session_state["delete_count"] = 0
    st.session_state["voice_flag"] = ""
    st.session_state["user_voice_value"] = ""
    st.session_state["error_info"] = ""
    st.session_state["current_chat_index"] = 0
    st.session_state["user_input_content"] = ""
    # è¯»å–å…¨å±€è®¾ç½®
    if os.path.exists("./set.json"):
        with open("./set.json", "r", encoding="utf-8") as f:
            data_set = json.load(f)
        for key, value in data_set.items():
            st.session_state[key] = value
    # è®¾ç½®å®Œæˆ
    st.session_state["initial_settings"] = True



# è¾“å…¥å†…å®¹å±•ç¤º
area_user_svg = st.empty()
area_user_content = st.empty()
# å›å¤å±•ç¤º
area_gpt_svg = st.empty()
area_gpt_content = st.empty()
# æŠ¥é”™å±•ç¤º
area_error = st.empty()

st.write("\n")
st.header("AIè‚²å„¿åŠ©æ‰‹")
tap_input, tab_func = st.tabs(
    ["ğŸ’¬ èŠå¤©",  "ğŸ› ï¸ åŠŸèƒ½"]
)

with tab_func:
    c1, c2, c3 = st.columns(3)

    st.write("\n")
    st.markdown("è‡ªå®šä¹‰åŠŸèƒ½ï¼š")
    c1, c2 = st.columns(2)
    with c1:
        if "open_text_toolkit_value" in st.session_state:
            default = st.session_state["open_text_toolkit_value"]
        else:
            default = True
        st.checkbox(
            "å¼€å¯æ–‡æœ¬ä¸‹çš„åŠŸèƒ½ç»„ä»¶",
            value=default,
            key="open_text_toolkit",
            
            args=("open_text_toolkit",),
        )
    with c2:
        if "open_voice_toolkit_value" in st.session_state:
            default = st.session_state["open_voice_toolkit_value"]
        else:
            default = True
        st.checkbox(
            "å¼€å¯è¯­éŸ³è¾“å…¥ç»„ä»¶",
            value=default,
            key="open_voice_toolkit",
        
            args=("open_voice_toolkit",),
        )

with tap_input:

    def input_callback():
        if st.session_state["user_input_area"] != "":
            # ä¿®æ”¹çª—å£åç§°
            user_input_content = st.session_state["user_input_area"]
            df_history = pd.DataFrame(st.session_state["history" + current_chat])
            if df_history.empty or len(df_history.query('role!="system"')) == 0:
                new_name = extract_chars(user_input_content, 18)
                reset_chat_name_fun(new_name)

    with st.form("input_form", clear_on_submit=True):
        user_input = st.text_area(
            "**è¾“å…¥ï¼š**",
            key="user_input_area",
            help="å†…å®¹å°†ä»¥Markdownæ ¼å¼åœ¨é¡µé¢å±•ç¤ºï¼Œå»ºè®®éµå¾ªç›¸å…³è¯­è¨€è§„èŒƒï¼ŒåŒæ ·æœ‰åˆ©äºGPTæ­£ç¡®è¯»å–ï¼Œä¾‹å¦‚ï¼š"
            "\n- ä»£ç å—å†™åœ¨ä¸‰ä¸ªåå¼•å·å†…ï¼Œå¹¶æ ‡æ³¨è¯­è¨€ç±»å‹"
            "\n- ä»¥è‹±æ–‡å†’å·å¼€å¤´çš„å†…å®¹æˆ–è€…æ­£åˆ™è¡¨è¾¾å¼ç­‰å†™åœ¨å•åå¼•å·å†…",
            value=st.session_state["user_voice_value"],
        )
        submitted = st.form_submit_button(
            "ç¡®è®¤æäº¤", use_container_width=True, on_click=input_callback
        )
    if submitted:
        st.session_state["user_input_content"] = user_input
        st.session_state["user_voice_value"] = ""
        st.experimental_rerun()

    if (
        "open_voice_toolkit_value" not in st.session_state
        or st.session_state["open_voice_toolkit_value"]
    ):
        # è¯­éŸ³è¾“å…¥åŠŸèƒ½
        vocie_result = voice_toolkit()
        # vocie_resultä¼šä¿å­˜æœ€åä¸€æ¬¡ç»“æœ
        if (
            vocie_result and vocie_result["voice_result"]["flag"] == "interim"
        ) or st.session_state["voice_flag"] == "interim":
            st.session_state["voice_flag"] = "interim"
            st.session_state["user_voice_value"] = vocie_result["voice_result"]["value"]
            if vocie_result["voice_result"]["flag"] == "final":
                st.session_state["voice_flag"] = "final"
                st.experimental_rerun()


def get_model_input():
    # éœ€è¾“å…¥çš„å†å²è®°å½•
    context_level = st.session_state["context_level" + current_chat]
    history = get_history_input(
        st.session_state["history" + current_chat], context_level
    ) + [{"role": "user", "content": st.session_state["pre_user_input_content"]}]
    for ctx in [
        st.session_state["context_input" + current_chat],
        set_context_all[st.session_state["context_select" + current_chat]],
    ]:
        if ctx != "":
            history = [{"role": "system", "content": ctx}] + history
    # è®¾å®šçš„æ¨¡å‹å‚æ•°
    paras = {
        "temperature": st.session_state["temperature" + current_chat],
        "top_p": st.session_state["top_p" + current_chat],
        "presence_penalty": st.session_state["presence_penalty" + current_chat],
        "frequency_penalty": st.session_state["frequency_penalty" + current_chat],
    }
    return history, paras


if st.session_state["user_input_content"] != "":
    if "r" in st.session_state:
        st.session_state.pop("r")
        st.session_state[current_chat + "report"] = ""
    st.session_state["pre_user_input_content"] = st.session_state["user_input_content"]
    st.session_state["user_input_content"] = ""
    # ä¸´æ—¶å±•ç¤º
    show_each_message(
        st.session_state["pre_user_input_content"],
        "user",
        "tem",
        [area_user_svg.markdown, area_user_content.markdown],
    )
    # æ¨¡å‹è¾“å…¥
    history_need_input, paras_need_input = get_model_input()
    # è°ƒç”¨æ¥å£
    with st.spinner("ğŸ¤”"):
        try:
            if apikey := st.session_state["apikey_input"]:
                openai.api_key = apikey
            # é…ç½®ä¸´æ—¶apikeyï¼Œæ­¤æ—¶ä¸ä¼šç•™å­˜èŠå¤©è®°å½•ï¼Œé€‚åˆå…¬å¼€ä½¿ç”¨
            elif "apikey_tem" in st.secrets:
                openai.api_key = st.secrets["apikey_tem"]
            # æ³¨ï¼šå½“st.secretsä¸­é…ç½®apikeyåå°†ä¼šç•™å­˜èŠå¤©è®°å½•ï¼Œå³ä½¿æœªä½¿ç”¨æ­¤apikey
            else:
                openai.api_key = st.secrets["apikey"]

                
            r = openai.ChatCompletion.create(
                model=st.session_state["select_model"],
                messages=history_need_input,
                stream=True,
                **paras_need_input,
            )
        except (FileNotFoundError, KeyError):
            area_error.error(
                "ç¼ºå¤± OpenAI API Keyï¼Œè¯·åœ¨å¤åˆ¶é¡¹ç›®åé…ç½®Secretsï¼Œæˆ–è€…åœ¨æ¨¡å‹é€‰é¡¹ä¸­è¿›è¡Œä¸´æ—¶é…ç½®ã€‚"
                "è¯¦æƒ…è§[é¡¹ç›®ä»“åº“](https://github.com/PierXuY/ChatGPT-Assistant)ã€‚"
            )
        except openai.error.AuthenticationError:
            area_error.error("æ— æ•ˆçš„ OpenAI API Keyã€‚")
        except openai.error.APIConnectionError as e:
            area_error.error("è¿æ¥è¶…æ—¶ï¼Œè¯·é‡è¯•ã€‚æŠ¥é”™ï¼š   \n" + str(e.args[0]))
        except openai.error.InvalidRequestError as e:
            area_error.error("æ— æ•ˆçš„è¯·æ±‚ï¼Œè¯·é‡è¯•ã€‚æŠ¥é”™ï¼š   \n" + str(e.args[0]))
        except openai.error.RateLimitError as e:
            area_error.error("è¯·æ±‚å—é™ã€‚æŠ¥é”™ï¼š   \n" + str(e.args[0]))
        else:
            st.session_state["chat_of_r"] = current_chat
            st.session_state["r"] = r
            st.experimental_rerun()

if ("r" in st.session_state) and (current_chat == st.session_state["chat_of_r"]):
    if current_chat + "report" not in st.session_state:
        st.session_state[current_chat + "report"] = ""
    try:
        for e in st.session_state["r"]:
            if "content" in e["choices"][0]["delta"]:
                st.session_state[current_chat + "report"] += e["choices"][0]["delta"][
                    "content"
                ]
                show_each_message(
                    st.session_state["pre_user_input_content"],
                    "user",
                    "tem",
                    [area_user_svg.markdown, area_user_content.markdown],
                )
                show_each_message(
                    st.session_state[current_chat + "report"],
                    "assistant",
                    "tem",
                    [area_gpt_svg.markdown, area_gpt_content.markdown],
                )
    except ChunkedEncodingError:
        area_error.error("ç½‘ç»œçŠ¶å†µä¸ä½³ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•ã€‚")
    # åº”å¯¹stopæƒ…å½¢
    except Exception:
        pass
    else:
        # ä¿å­˜å†…å®¹
        st.session_state["history" + current_chat].append(
            {"role": "user", "content": st.session_state["pre_user_input_content"]}
        )
        st.session_state["history" + current_chat].append(
            {"role": "assistant", "content": st.session_state[current_chat + "report"]}
        )
        write_data()
    # ç”¨æˆ·åœ¨ç½‘é¡µç‚¹å‡»stopæ—¶ï¼ŒssæŸäº›æƒ…å½¢ä¸‹ä¼šæš‚æ—¶ä¸ºç©º
    if current_chat + "report" in st.session_state:
        st.session_state.pop(current_chat + "report")
    if "r" in st.session_state:
        st.session_state.pop("r")
        st.experimental_rerun()

# æ·»åŠ äº‹ä»¶ç›‘å¬
v1.html(js_code, height=0)
